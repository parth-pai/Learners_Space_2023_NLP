{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parth-pai/Learners_Space_2023_NLP/blob/main/LS_Gradio_Run_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Mounting Drive**\n",
        "First we mount the google drive here to access the required files"
      ],
      "metadata": {
        "id": "yOSyP10ss3nE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iod2CiGnm9C",
        "outputId": "f5662837-44f7-4d45-dbf6-3f09a8cbb1ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install required libraries again here as done in Training code"
      ],
      "metadata": {
        "id": "UftTXc3ctEH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio transformers sentencepiece"
      ],
      "metadata": {
        "id": "34OZ1dPEn_0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Displaying using Gradio**\n",
        "Now we create an interactive app environment using `gradio`. We can see language translation happening with this good looking and interactive app interface."
      ],
      "metadata": {
        "id": "ssIvx0O_XeW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, pipeline, AutoTokenizer\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "aXNwmCQmofdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First input the model, the tokenizer and translation pipeline. Then define the function that gradio will be using and input required arguments into gradio giving title and description. Then launch the interface using `iface.launch()`"
      ],
      "metadata": {
        "id": "3xbtLJmntR1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = AutoModelForSeq2SeqLM.from_pretrained('/content/drive/MyDrive/LS_NLP_Parth')\n",
        "tokenizer=AutoTokenizer.from_pretrained('/content/drive/MyDrive/LS_NLP_Parth')\n",
        "translator = pipeline(\"translation\", model=model_checkpoint)\n",
        "def translation(text):\n",
        "  return translator(text)[0]['translation_text']\n",
        "iface = gr.Interface(\n",
        "    fn=translation,\n",
        "    inputs=gr.inputs.Textbox(label=\"Input English Text\"),\n",
        "    outputs=gr.outputs.Textbox(label=\"Translated Italian Text\"),\n",
        "    title=\"English to Italian Translation\",\n",
        "    description=\"Translate English text to Italian using a fine-tuned model.\",\n",
        ")\n",
        "\n",
        "iface.launch()"
      ],
      "metadata": {
        "id": "dPtYKVNCsa_5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}